<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>LILAC: Long-sequence Incremental Low-Latency And Causal Stylization</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px auto;
      max-width: 900px;
      line-height: 1.6;
    }
    h1 {
      font-size: 28px;
      margin-bottom: 10px;
      text-align: center;
    }
    h2 {
      border-bottom: 2px solid #ddd;
      padding-bottom: 4px;
      margin-top: 40px;
    }
    .slogan {
      font-size: 18px;
      font-style: italic;
      color: #444;
      text-align: center;
      margin-bottom: 20px;
    }
    .center {
      text-align: center;
    }
    video, img, iframe {
      display: block;
      margin: 0 auto;
      border-radius: 8px;
    }
    ol {
      margin-left: 20px;
    }
    .caption {
      font-size: 14px;
      color: #666;
      text-align: center;
      margin-top: 8px;
    }
  </style>
</head>

<body>

  <!-- ===== Title & Slogan ===== -->
  <h1>LILAC: Long-sequence Incremental Low-Latency And Causal Stylization</h1>
  <p class="slogan">
    Real-time streaming motion stylization with low latency and long-sequence temporal consistency.
  </p>
  
  <p style="text-align:center; margin-top:10px;">
    ðŸ“„ <a href="https://arxiv.org/abs/xxxx.xxxxx" target="_blank">View on arXiv</a>
  </p>

  <!-- ===== Embedded Demo Video (21:9 aspect ratio) ===== -->
  <div class="center" style="position: relative; width: 100%; max-width: 900px; padding-top: 42.86%; margin: 0 auto;">
    <iframe 
      src="https://drive.google.com/file/d/16_OsIK2DPEWhT2IhKNPGNhUEyhcqftZv/preview"
      style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: none;"
      allow="autoplay">
    </iframe>
  </div>
  <p class="caption">(Watch: Real-time stylized motion generation demo)</p>
  
  <!-- ===== Teaser GIF ===== -->
  <div class="center" style="margin-top:30px;">
    <img src="assets/walk_circle_hands_high_537_scale_2-516-ezgif.com-optimize.gif" 
         width="900" alt="Teaser figure showing long-sequence stylized motion generation">
    <p class="caption">(Long-sequence streaming motion stylization results)</p>
  </div>

  <!-- ===== Abstract ===== -->
  <h2>Abstract</h2>
  <p>
    Generating long and stylized human motions in real time is critical for applications that demand continuous and responsive character control.
    While existing VAEâ€“Diffusion models achieve high-quality stylization in the latent space, they are confined to offline processing.
    In contrast, most prior streaming approaches operate directly in the raw motion space, which incurs substantial computational overhead and makes it difficult to maintain temporal stability.
    We propose <b>LILAC</b> (Long-sequence Incremental Low-Latency And Causal stylization), a framework for long-sequence streaming motion stylization in the latent space.
    LILAC refines latent motion vectors through a diffusion model with low-latency updates and employs a transformer-based causal decoder to assemble them into temporally consistent sequences.
    This design enables real-time generation with smooth and immediate style transitions, achieving a favorable balance between stylization quality and responsiveness as demonstrated by experiments on benchmark datasets.
  </p>

  <!-- ===== Method Overview ===== -->
  <h2>Method Overview</h2>
  <p>The proposed framework makes three main contributions:</p>

  <ol>
    <li>
      <b>Latent-space streaming architecture.</b>
      A causal sliding-window design enables real-time motion stylization without access to future frames or modifications to the diffusion model.
    </li>
    <li>
      <b>Style-conditioned generation.</b>
      Incorporates MotionCLIP style embeddings&nbsp;<a href="https://arxiv.org/abs/2203.13406" target="_blank">[Tevet&nbsp;et&nbsp;al.,&nbsp;2022]</a>,
      allowing smooth and instantaneous transitions between motion styles during streaming.
    </li>
    <li>
      <b>Experimental validation.</b>
      Benchmarks demonstrate the practicality and effectiveness of the proposed streaming framework compared with offline methods.
    </li>
  </ol>

  <div class="center">
    <img src="assets/Diffusion.drawio.png"
         style="max-width: 500px; width: 90%; height: auto; border-radius: 6px;"
         alt="Method diagram">
    <p class="caption" style="max-width: 600px; margin: 10px auto; font-size: 14px; color: #555;">
      <b>Figure:</b> Proposed streaming stylization pipeline.
      Motion segments are processed by an encoderâ€“decoder with a style-conditioned denoiser.
      The latent output of the diffusion model is decoded into motion features,
      concatenated with previous outputs, aligned through trajectory copy, re-encoded,
      and passed into a causal decoder for temporally consistent motion generation.
    </p>
  </div>
  <!-- ===== Results ===== -->
  <h2>Results</h2>
  <p>
    We present both quantitative and qualitative results demonstrating that the proposed streaming framework maintains high stylization quality and temporal consistency while achieving real-time performance.
  </p>
  
  <!-- ===== Quantitative Table ===== -->
  <h3>Quantitative Comparison</h3>
  <div style="overflow-x:auto;">
    <table style="width:100%; border-collapse:collapse; text-align:center; font-size:15px;">
      <thead>
        <tr style="border-bottom:2px solid #666;">
          <th style="text-align:left;">Methods</th>
          <th>FMD â†“</th>
          <th>CRA â†‘</th>
          <th>SRA â†‘</th>
          <th>Total&nbsp;Jitter â†“</th>
        </tr>
      </thead>
      <tbody>
        <tr style="border-bottom:1px solid #ddd;">
          <td style="text-align:left;">Real Motions</td>
          <td>--</td><td>0.99</td><td>1.00</td><td>--</td>
        </tr>
        <tr style="border-bottom:1px solid #ddd;">
          <td style="text-align:left;">1DConv + AdaIN</td>
          <td>42.68</td><td>0.31</td><td>0.57</td><td>--</td>
        </tr>
        <tr style="border-bottom:1px solid #ddd;">
          <td style="text-align:left;">STGCN + AdaIN</td>
          <td>129.44</td><td><b>0.60</b></td><td>0.18</td><td>--</td>
        </tr>
        <tr style="border-bottom:1px solid #ddd;">
          <td style="text-align:left;">Motion Puzzle</td>
          <td>113.31</td><td>0.26</td><td>0.46</td><td>--</td>
        </tr>
        <tr style="border-bottom:2px solid #666;">
          <td style="text-align:left;">Offline (Original Paper)</td>
          <td><b>27.69</b></td><td>0.36</td><td>0.58</td><td><b>0.0089</b></td>
        </tr>
        <tr>
          <td style="text-align:left;"><b>Online (Proposed, 10 steps)</b></td>
          <td>31.69</td><td>0.30</td><td><b>0.58</b></td><td>0.0139</td>
        </tr>
      </tbody>
    </table>
  </div>
  
  <p style="font-size:14px; color:#666; text-align:center; margin-top:8px;">
    <b>Table:</b> Quantitative comparison between offline and proposed streaming settings.
    LILAC achieves a favorable balance between stylization quality and real-time performance.
  </p>
  
  <!-- ===== Qualitative GIFs ===== -->
  <h3>Qualitative Results</h3>
  <p>
    Representative long-sequence stylization results demonstrate temporal coherence, smooth transitions, and responsiveness under different motion styles and trajectories.
  </p>
  
  <div class="center">
    <img src="assets/result_1.gif" width="900" style="margin-top:20px;">
    <img src="assets/result_2.gif" width="900" style="margin-top:20px;">
    <img src="assets/result_3.gif" width="900" style="margin-top:20px;">
    <p class="caption">
      Each sequence shows real-time generated motions under different style embeddings or trajectories.
    </p>
  </div>

  <!-- ===== Footer ===== -->
  <p style="text-align:center; font-size:14px; color:#666; margin-top:40px;">
    Project page for <b>LILAC</b>. Last updated: October 2025.<br>
  </p>

</body>
</html>
